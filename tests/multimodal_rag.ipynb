{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install setuptools==69.5.1 numpy==1.21.3 torch torchvision ftfy faiss-cpu==1.7.4 openai-clip langchain langchain-community langchain-experimental langchain-openai open_clip_torch 'arize-phoenix[evals]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "import glob\n",
    "paths = glob.glob('./images/*.jpeg', recursive=True)\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yujian/Documents/workspace/rag_cookbooks/p310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "üìñ For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "import phoenix as px\n",
    "session = px.launch_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.trace.langchain import LangChainInstrumentor\n",
    "\n",
    "LangChainInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.open_clip import OpenCLIPEmbeddings\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_docs = []\n",
    "def encode_image(path):\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "for path in paths:\n",
    "    doc = Document(\n",
    "        page_content=encode_image(path),\n",
    "        lookup_str = '',\n",
    "        metadata ={\n",
    "            'source': path\n",
    "        },\n",
    "        lookup_index=0\n",
    "    )\n",
    "    lc_docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS.from_documents(lc_docs, embedding=OpenCLIPEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def resize_base64_image(base64_string, size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Resize an image encoded as a Base64 string.\n",
    "\n",
    "    Args:\n",
    "    base64_string (str): Base64 string of the original image.\n",
    "    size (tuple): Desired size of the image as (width, height).\n",
    "\n",
    "    Returns:\n",
    "    str: Base64 string of the resized image.\n",
    "    \"\"\"\n",
    "    # Decode the Base64 string\n",
    "    img_data = base64.b64decode(base64_string)\n",
    "    img = Image.open(io.BytesIO(img_data))\n",
    "\n",
    "    # Resize the image\n",
    "    resized_img = img.resize(size, Image.LANCZOS)\n",
    "\n",
    "    # Save the resized image to a bytes buffer\n",
    "    buffered = io.BytesIO()\n",
    "    resized_img.save(buffered, format=img.format)\n",
    "\n",
    "    # Encode the resized image to Base64\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def is_base64(s):\n",
    "    \"\"\"Check if a string is Base64 encoded\"\"\"\n",
    "    try:\n",
    "        return base64.b64encode(base64.b64decode(s)) == s.encode()\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def split_image_text_types(docs):\n",
    "    \"\"\"Split numpy array images and texts\"\"\"\n",
    "    images = []\n",
    "    text = []\n",
    "    for doc in docs:\n",
    "        doc = doc.page_content  # Extract Document contents\n",
    "        if is_base64(doc):\n",
    "            # Resize image to avoid OAI server error\n",
    "            images.append(\n",
    "                resize_base64_image(doc, size=(250, 250))\n",
    "            )  # base64 encoded str\n",
    "        else:\n",
    "            text.append(doc)\n",
    "    return {\"images\": images, \"texts\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "def prompt_func(data_dict):\n",
    "    # Joining the context texts into a single string\n",
    "    formatted_texts = \"\\n\".join(data_dict[\"context\"][\"texts\"])\n",
    "    messages = []\n",
    "\n",
    "    # Adding image(s) to the messages if present\n",
    "    if data_dict[\"context\"][\"images\"]:\n",
    "        image_message = {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{data_dict['context']['images'][0]}\"\n",
    "            },\n",
    "        }\n",
    "        messages.append(image_message)\n",
    "\n",
    "    # Adding the text message for analysis\n",
    "    text_message = {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": (\n",
    "            \"As an animal lover, your task is to analyze and interpret images of cute animals, \"\n",
    "            \"Please use your extensive knowledge and analytical skills to provide a \"\n",
    "            \"summary that includes:\\n\"\n",
    "            \"- A detailed description of the visual elements in the image.\\n\"\n",
    "            f\"User-provided keywords: {data_dict['question']}\\n\\n\"\n",
    "            \"Text and / or tables:\\n\"\n",
    "            f\"{formatted_texts}\"\n",
    "        ),\n",
    "    }\n",
    "    messages.append(text_message)\n",
    "\n",
    "    return [HumanMessage(content=messages)]\n",
    "\n",
    "\n",
    "foundation = ChatOpenAI(temperature=0, model=\"gpt-4-vision-preview\", max_tokens=1024)\n",
    "\n",
    "# RAG pipeline\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever | RunnableLambda(split_image_text_types),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | RunnableLambda(prompt_func)\n",
    "    | foundation\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR [openinference.instrumentation.langchain._tracer] Failed to get attribute.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yujian/Documents/workspace/rag_cookbooks/p310/lib/python3.10/site-packages/openinference/instrumentation/langchain/_tracer.py\", line 274, in wrapper\n",
      "    yield from wrapped(*args, **kwargs)\n",
      "  File \"/Users/yujian/Documents/workspace/rag_cookbooks/p310/lib/python3.10/site-packages/openinference/instrumentation/langchain/_tracer.py\", line 426, in _parse_message_data\n",
      "    assert isinstance(content, str), f\"expected str, found {type(content)}\"\n",
      "AssertionError: expected str, found <class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The image shows a German Shepherd dog standing on a grassy surface. The dog is positioned in profile, allowing a clear view of its body structure and markings. The German Shepherd has a well-defined, muscular build, indicative of the breed's strength and agility. Its coat is predominantly tan with a black saddle marking that extends over the back and sides, and the black coloration continues onto the tail. The dog's face has the characteristic black mask, with black coloration around the eyes, ears, and extending down the muzzle.\\n\\nThe German Shepherd's ears are erect and pointed, which is typical for the breed and suggests attentiveness or interest in its environment. Its eyes are not clearly visible in the image, but the direction of its gaze seems forward, possibly focusing on something or someone outside of the frame. The dog's tongue is out, which could indicate that it is panting, possibly due to exercise or warm weather.\\n\\nThe background is blurred but appears to be a garden or park setting with various green plants and possibly a fence in the distance. The focus on the dog against the soft background emphasizes the animal and allows for a detailed observation of its features.\\n\\nOverall, the image captures the noble and alert demeanor of the German Shepherd, showcasing the breed's physical characteristics and the beauty of its coat pattern and coloration.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"german shepard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': './images/dog_1.jpeg'}\n",
      "{'source': './images/cat_5.jpeg'}\n",
      "{'source': './images/cat_4.jpeg'}\n",
      "{'source': './images/cat_3.jpeg'}\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.invoke(\"german shepard\", k=3)\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR [openinference.instrumentation.langchain._tracer] Failed to get attribute.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yujian/Documents/workspace/rag_cookbooks/p310/lib/python3.10/site-packages/openinference/instrumentation/langchain/_tracer.py\", line 274, in wrapper\n",
      "    yield from wrapped(*args, **kwargs)\n",
      "  File \"/Users/yujian/Documents/workspace/rag_cookbooks/p310/lib/python3.10/site-packages/openinference/instrumentation/langchain/_tracer.py\", line 426, in _parse_message_data\n",
      "    assert isinstance(content, str), f\"expected str, found {type(content)}\"\n",
      "AssertionError: expected str, found <class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The image shows a cat lying down on a carpeted floor, not a white background as mentioned in the keywords. The cat appears to be a domestic short-haired with a tabby pattern, characterized by its striped and mottled coat of gray and black. Its eyes are a striking green, and they are wide open, giving the cat an alert and curious expression.\\n\\nThe cat is resting on its side, with its head turned towards the camera, allowing for a clear view of its face. One of its front paws is stretched out, while the other seems to be tucked underneath its body. The cat's ears are in a neutral position, neither flattened nor perked up, which usually indicates a state of relaxation or contentment.\\n\\nIn the background, there is a small blue ball, suggesting that the cat may have been playing before settling down in this position. The carpet is a neutral color, providing a soft texture that contrasts with the cat's fur. The lighting in the image is soft and diffused, casting gentle shadows and highlighting the cat's fur texture and the details of its face.\\n\\nOverall, the image captures a serene moment of a cat at rest, with visual elements that emphasize its relaxed posture and the softness of its environment.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"cat laying down on white background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': './images/cat_4.jpeg'}\n",
      "{'source': './images/dog_1.jpeg'}\n",
      "{'source': './images/cat_5.jpeg'}\n",
      "{'source': './images/cat_3.jpeg'}\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.invoke(\"cat laying down on white background\", k=3)\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': './images/cat_4.jpeg'}\n",
      "{'source': './images/dog_1.jpeg'}\n",
      "{'source': './images/cat_5.jpeg'}\n",
      "{'source': './images/dog_4.jpeg'}\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.invoke(\"cat showing teeth with open mouth\", k=3)\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR [openinference.instrumentation.langchain._tracer] Failed to get attribute.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yujian/Documents/workspace/rag_cookbooks/p310/lib/python3.10/site-packages/openinference/instrumentation/langchain/_tracer.py\", line 274, in wrapper\n",
      "    yield from wrapped(*args, **kwargs)\n",
      "  File \"/Users/yujian/Documents/workspace/rag_cookbooks/p310/lib/python3.10/site-packages/openinference/instrumentation/langchain/_tracer.py\", line 426, in _parse_message_data\n",
      "    assert isinstance(content, str), f\"expected str, found {type(content)}\"\n",
      "AssertionError: expected str, found <class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The image shows a close-up of a cat lying on its side on a carpeted floor. The cat appears to be a domestic short-haired with a tabby pattern, characterized by its striped fur in shades of gray and black, with a hint of brown. Its eyes are a striking green color, wide open and looking directly at the camera, which adds to its engaging expression.\\n\\nThe cat's mouth is slightly open, revealing its small white teeth, which could be interpreted as a playful gesture or a mid-yawn moment. The cat's right paw is extended towards the camera, adding to the playful or relaxed demeanor. The soft focus of the image emphasizes the cat's face, particularly its eyes and mouth.\\n\\nIn the background, there is a small blue ball, which could suggest that the cat was playing before the photo was taken. The overall impression is that of a content and relaxed cat in a comfortable home environment. The cat's expression and body language exude a sense of calm and comfort, making the image quite endearing to viewers, especially those who appreciate the charm of feline companions.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"cat showing teeth with open mouth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
